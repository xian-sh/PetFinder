{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64949a20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T12:15:17.319805Z",
     "iopub.status.busy": "2021-12-04T12:15:17.318792Z",
     "iopub.status.idle": "2021-12-04T12:15:17.374864Z",
     "shell.execute_reply": "2021-12-04T12:15:17.373944Z",
     "shell.execute_reply.started": "2021-12-04T11:20:21.876471Z"
    },
    "papermill": {
     "duration": 0.08291,
     "end_time": "2021-12-04T12:15:17.375066",
     "exception": false,
     "start_time": "2021-12-04T12:15:17.292156",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#可以手动打乱原始数据集，直接在excel表中操作\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "\n",
    "#数据集地址\n",
    "data_dir = '../input/petfinder-pawpularity-score'\n",
    "origin_dir = os.path.join(data_dir,'train.csv')\n",
    "train_dir = './train_data.csv'\n",
    "\n",
    "train_file = open(train_dir,'w',newline='')\n",
    "#读取源数据地址，在train.csv文件夹下\n",
    "with open(origin_dir,'r') as f:\n",
    "    lines = f.readlines()[1:] #  去掉跳过文件头行\n",
    "f.close()\n",
    "#打乱读入的每一行数据（样例顺序打乱）\n",
    "random.shuffle(lines)\n",
    "#写文件\n",
    "train_writer = csv.writer(train_file)\n",
    "\n",
    "for i in range(len(lines)):\n",
    "    temp = lines[i].rsplit('\\n')[0].split(',')\n",
    "    # 取大约80%的样例为训练集，剩余的为测试集\n",
    "    if i <= 2000:\n",
    "        train_writer.writerow(temp)\n",
    "\n",
    "train_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "733df4f4",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-12-04T12:15:17.428546Z",
     "iopub.status.busy": "2021-12-04T12:15:17.391607Z",
     "iopub.status.idle": "2021-12-04T12:18:37.318079Z",
     "shell.execute_reply": "2021-12-04T12:18:37.317230Z",
     "shell.execute_reply.started": "2021-12-04T11:53:34.117159Z"
    },
    "papermill": {
     "duration": 199.935776,
     "end_time": "2021-12-04T12:18:37.318236",
     "exception": false,
     "start_time": "2021-12-04T12:15:17.382460",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练数据集的长度为：2000\n",
      "---------------------第 1 轮训练开始---------------------\n",
      "epoch 1, iter20, loss: 0.0719\n",
      "epoch 1在整体训练集上的平均损失: 0.0736\n",
      "epoch 1在整体训练集上的正确率: 3.1500%\n",
      "Find Better Model and Saving it...\n",
      "Saved!\n",
      "Training complete in 0m 50s\n",
      "Now the minimum loss is 0.0736\n",
      "---------------------第 2 轮训练开始---------------------\n",
      "epoch 2, iter20, loss: 0.0718\n",
      "epoch 2在整体训练集上的平均损失: 0.0735\n",
      "epoch 2在整体训练集上的正确率: 2.9500%\n",
      "Find Better Model and Saving it...\n",
      "Saved!\n",
      "Training complete in 0m 35s\n",
      "Now the minimum loss is 0.0735\n",
      "---------------------第 3 轮训练开始---------------------\n",
      "epoch 3, iter20, loss: 0.0717\n",
      "epoch 3在整体训练集上的平均损失: 0.0735\n",
      "epoch 3在整体训练集上的正确率: 3.2000%\n",
      "Find Better Model and Saving it...\n",
      "Saved!\n",
      "Training complete in 0m 36s\n",
      "Now the minimum loss is 0.0735\n",
      "---------------------第 4 轮训练开始---------------------\n",
      "epoch 4, iter20, loss: 0.0716\n",
      "epoch 4在整体训练集上的平均损失: 0.0734\n",
      "epoch 4在整体训练集上的正确率: 3.4000%\n",
      "Find Better Model and Saving it...\n",
      "Saved!\n",
      "Training complete in 0m 36s\n",
      "Now the minimum loss is 0.0734\n",
      "---------------------第 5 轮训练开始---------------------\n",
      "epoch 5, iter20, loss: 0.0715\n",
      "epoch 5在整体训练集上的平均损失: 0.0733\n",
      "epoch 5在整体训练集上的正确率: 3.5500%\n",
      "Find Better Model and Saving it...\n",
      "Saved!\n",
      "Training complete in 0m 36s\n",
      "Now the minimum loss is 0.0733\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "try:\n",
    "    from torch.hub import load_state_dict_from_url\n",
    "except ImportError:\n",
    "    from torch.utils.model_zoo import load_url as load_state_dict_from_url\n",
    "\n",
    "\n",
    "__all__ = [\n",
    "    'VGG', 'vgg16',\n",
    "]\n",
    "\n",
    "\n",
    "model_urls = {\n",
    "    'vgg16': 'https://download.pytorch.org/models/vgg16-397923af.pth',\n",
    "}\n",
    "\n",
    "\n",
    "class VGG(nn.Module):\n",
    "\n",
    "    def __init__(self, features, num_classes=1000, init_weights=True):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = features\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((7, 7))\n",
    "        ##将VGG16的特征提取层参数进行冻结，不对其进行更新\n",
    "        for param in self.features.parameters():\n",
    "            param.requires_grad_(False)\n",
    "        self.Line = nn.Sequential(\n",
    "            nn.Linear(512 * 7 * 7, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 256)\n",
    "        )\n",
    "        self.model2 = nn.Sequential(\n",
    "            nn.Linear(12, 128),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(128, 256)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(  # 定义自己的分类层\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 100)\n",
    "        )\n",
    "        if init_weights:\n",
    "            self._initialize_weights()\n",
    "\n",
    "    def forward(self, input1, input2):\n",
    "        s = input1.size(0)\n",
    "        input1 = self.features(input1)\n",
    "        input1 = input1.view(s, -1)\n",
    "        input1 = self.Line(input1)\n",
    "        input1 = input1.view(s, -1)\n",
    "\n",
    "        input2 = input2.view(s, -1)\n",
    "        input2 = self.model2(input2)\n",
    "        input2 = input2.view(s, -1)\n",
    "\n",
    "        Input = torch.cat([input1, input2], dim=1)\n",
    "        output = self.classifier(Input)\n",
    "        return output\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "\n",
    "\n",
    "def make_layers(cfg, batch_norm=False):\n",
    "    layers = []\n",
    "    in_channels = 3\n",
    "    for v in cfg:\n",
    "        if v == 'M':\n",
    "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "        else:\n",
    "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
    "            if batch_norm:\n",
    "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
    "            else:\n",
    "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
    "            in_channels = v\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "cfgs = {\n",
    "    'A': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'B': [64, 64, 'M', 128, 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
    "    'D': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
    "    'E': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M', 512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'],\n",
    "}\n",
    "\n",
    "\n",
    "def _vgg(arch, cfg, batch_norm, pretrained, progress, **kwargs):\n",
    "    if pretrained:\n",
    "        kwargs['init_weights'] = False\n",
    "    model = VGG(make_layers(cfgs[cfg], batch_norm=batch_norm), **kwargs)\n",
    "    if pretrained:\n",
    "        state_dict = load_state_dict_from_url(model_urls[arch],\n",
    "                                              progress=progress)\n",
    "        model.load_state_dict(state_dict)\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg16(pretrained=False, progress=True, **kwargs):\n",
    "    r\"\"\"VGG 16-layer model (configuration \"D\")\n",
    "    `\"Very Deep Convolutional Networks For Large-Scale Image Recognition\" <https://arxiv.org/pdf/1409.1556.pdf>`_\n",
    "\n",
    "    Args:\n",
    "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
    "        progress (bool): If True, displays a progress bar of the download to stderr\n",
    "    \"\"\"\n",
    "    return _vgg('vgg16', 'D', False, pretrained, progress, **kwargs)\n",
    "\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "class MyData(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, image_dir, label_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.label_path = os.path.join(self.root_dir, self.label_dir)\n",
    "        self.image_path = os.path.join(self.root_dir, self.image_dir)\n",
    "        self.image_list = os.listdir(self.image_path)\n",
    "        self.transform = transform\n",
    "\n",
    "        with open(self.label_path, 'r') as f:\n",
    "            self.data = f.readlines()[1:]  # 去掉跳过文件头行\n",
    "        f.close()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data[idx].rsplit('\\n')[0].split(',')[0] + '.jpg'\n",
    "        img_item_path = os.path.join(self.root_dir, self.image_dir, img_name)\n",
    "        img = Image.open(img_item_path)\n",
    "        feature = [float(x) for x in self.data[idx].rsplit('\\n')[0].split(',')[1:13]]\n",
    "        target = int(self.data[idx].rsplit('\\n')[0].split(',')[13])-1\n",
    "        img = self.transform(img)\n",
    "        # trans_norm = transforms.Normalize([0.5, 0.5, 0.5])\n",
    "        # trans_norm1 = transforms.Normalize([0.5,])\n",
    "        # img = trans_norm(img)\n",
    "        feature = torch.as_tensor(feature)\n",
    "        feature = torch.reshape(feature, (1, 1, -1))\n",
    "        # feature = trans_norm1(feature)\n",
    "        label = torch.as_tensor(target)\n",
    "        return img, feature, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = torch.device(\"cpu\")\n",
    "# 准备数据集\n",
    "# 这里把PetFInder作为根目录，右击该文件夹->Make Directory as...->root\n",
    "root_dir = \"/kaggle/input/petfinder-pawpularity-score\"\n",
    "image1_dir = \"train\"\n",
    "label1_dir = \"./train_data.csv\"\n",
    "dataset_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),  # 随机长宽比裁剪为224*224\n",
    "    transforms.RandomHorizontalFlip(),  # 依概率p=0.5水平翻转\n",
    "    transforms.ToTensor(),  # 转化为张量并归一化为[0-1]\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "train_dataset = MyData(\"\", os.path.join(root_dir, image1_dir), label1_dir, transform=dataset_transform)\n",
    "\n",
    "# length 长度\n",
    "train_data_size = len(train_dataset)\n",
    "# 如果train_data_size=10, 训练数据集的长度为：10\n",
    "print(\"训练数据集的长度为：{}\".format(train_data_size))\n",
    "\n",
    "# 格式转换\n",
    "# 利用 DataLoader 来加载数据集\n",
    "batch = 64\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch, drop_last=False)\n",
    "# 创建网络模型\n",
    "model = vgg16(pretrained=False)\n",
    "# 第一次运行时将下面导入权值的代码注释掉\n",
    "#model.load_state_dict(torch.load('./VGG16_Cats_Dogs_loss.pth'))\n",
    "model = model.to(device)\n",
    "\n",
    "# 损失函数\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "loss_fn = loss_fn.to(device)\n",
    "optimizer = torch.optim.SGD(model.classifier.parameters(), lr=0.01, momentum=0.5)\n",
    "\n",
    "# 保存每个epoch后的Accuracy Loss Val_Accuracy\n",
    "Accuracy = []\n",
    "Loss = []\n",
    "Val_Accuracy = []\n",
    "BEST_VAL_ACC = 0.\n",
    "BEST_TR_ACC = 0.\n",
    "Min_Loss = 100.\n",
    "# 第一次运行时将下面导入当前最小损失值的代码注释掉\n",
    "#Min_Loss = np.loadtxt('./vgg_loss_acc.txt')\n",
    "# 训练\n",
    "\n",
    "for epoch in range(5):\n",
    "    print(\"---------------------第 {} 轮训练开始---------------------\".format(epoch + 1))\n",
    "    since = time.time()\n",
    "    total_train_loss = 0.\n",
    "    total_accuracy = 0.\n",
    "    model.train()\n",
    "    for i,(imgs, feature, labels) in enumerate(train_dataloader, 0):\n",
    "        imgs = imgs.to(device)\n",
    "        feature = feature.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # 优化器优化模型\n",
    "        optimizer.zero_grad()\n",
    "        outs = model(imgs, feature)\n",
    "        loss = loss_fn(outs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #      输出状态\n",
    "        total_train_loss = total_train_loss + loss.item()\n",
    "        _, prediction = torch.max(outs, 1)\n",
    "        total_accuracy += (prediction == labels).sum().item()\n",
    "\n",
    "        if i % 20 == 19:\n",
    "            print('epoch {}, iter{}, loss: {:.4f}'.format(epoch+1,i+1, loss.item() / batch))\n",
    "    Loss.append(total_train_loss / train_data_size)\n",
    "    Accuracy.append(total_accuracy / train_data_size)\n",
    "    print(\"epoch {}在整体训练集上的平均损失: {:.4f}\".format(epoch+1,total_train_loss / train_data_size))\n",
    "    print(\"epoch {}在整体训练集上的正确率: {:.4f}%\".format(epoch+1,100*total_accuracy / train_data_size))\n",
    "    if Loss[epoch] < Min_Loss:\n",
    "        print('Find Better Model and Saving it...')\n",
    "        torch.save(model.state_dict(), './VGG16_Cats_Dogs_loss.pth')\n",
    "        Min_Loss = Loss[epoch]\n",
    "        ACC = []\n",
    "        ACC.append(Min_Loss)\n",
    "        np.savetxt('./vgg_loss_acc.txt',ACC,fmt='%.04f' )\n",
    "        print('Saved!')\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Now the minimum loss is {:.4f}'.format(Min_Loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7cd722b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-12-04T12:18:37.354607Z",
     "iopub.status.busy": "2021-12-04T12:18:37.353210Z",
     "iopub.status.idle": "2021-12-04T12:18:38.028277Z",
     "shell.execute_reply": "2021-12-04T12:18:38.028851Z",
     "shell.execute_reply.started": "2021-12-04T12:11:38.055898Z"
    },
    "papermill": {
     "duration": 0.700055,
     "end_time": "2021-12-04T12:18:38.029026",
     "exception": false,
     "start_time": "2021-12-04T12:18:37.328971",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67.75, 59.15, 20.02, 94.53, 89.82, 65.5, 71.42, 5.85]\n",
      "[27.01, 27.01, 27.01, 27.01, 27.01, 27.01, 27.01, 27.01]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "class TestData(Dataset):\n",
    "\n",
    "    def __init__(self, root_dir, image_dir, label_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_dir = image_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.label_path = os.path.join(self.root_dir, self.label_dir)\n",
    "        self.image_path = os.path.join(self.root_dir, self.image_dir)\n",
    "        self.image_list = os.listdir(self.image_path)\n",
    "        self.transform = transform\n",
    "\n",
    "        with open(self.label_path, 'r') as f:\n",
    "            self.data = f.readlines()[1:]  # 去掉跳过文件头行\n",
    "        f.close()\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = self.data[idx].rsplit('\\n')[0].split(',')[0] + '.jpg'\n",
    "        img_item_path = os.path.join(self.root_dir, self.image_dir, img_name)\n",
    "        img = Image.open(img_item_path)\n",
    "        feature = [float(x) for x in self.data[idx].rsplit('\\n')[0].split(',')[1:13]]\n",
    "        img = self.transform(img)\n",
    "        feature = torch.as_tensor(feature)\n",
    "        feature = torch.reshape(feature, (1, 1, -1))\n",
    "        return img, feature\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "#准备数据集\n",
    "root_dir = \"/kaggle/input/petfinder-pawpularity-score\"\n",
    "label3_dir = \"test.csv\"\n",
    "dataset_transform = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),  # 随机长宽比裁剪为224*224\n",
    "    transforms.RandomHorizontalFlip(),  # 依概率p=0.5水平翻转\n",
    "    transforms.ToTensor(),  # 转化为张量并归一化为[0-1]\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])\n",
    "test = TestData(root_dir,\"test\",label3_dir,transform=dataset_transform)\n",
    "test_dataloader = DataLoader(test, batch_size=8, drop_last=False)\n",
    "\n",
    "# 创建网络模型\n",
    "model = vgg16(pretrained=False)\n",
    "# 第一次运行时将下面导入权值的代码注释掉\n",
    "model.load_state_dict(torch.load('./VGG16_Cats_Dogs_loss.pth'))\n",
    "model = model.to(device)\n",
    "# 测试\n",
    "pred_list = []\n",
    "with open(os.path.join(root_dir, 'sample_submission.csv'), 'r') as f:\n",
    "    test_label = f.readlines()[1:] # 去掉跳过文件头行\n",
    "f.close()\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for data in test_dataloader:\n",
    "        imgs, feature = data\n",
    "        imgs = imgs.to(device)\n",
    "        feature = feature.to(device)\n",
    "        out = model(imgs, feature)\n",
    "        _, prediction = torch.max(out, 1)\n",
    "id_list = []\n",
    "targets = []\n",
    "for i in range(len(test_label)):\n",
    "    id_list.append(test_label[i].rsplit('\\n')[0].split(',')[0])\n",
    "    targets.append(float(test_label[i].rsplit('\\n')[0].split(',')[1]))\n",
    "pred_list = prediction.cuda().data.cpu().numpy()\n",
    "pred_list = list(pred_list)\n",
    "for i in range(len(pred_list)):\n",
    "    pred_list[i] = float('%.02f' % (float(int(pred_list[i]))+0.01))\n",
    "print(targets)\n",
    "print(pred_list)\n",
    "res = pd.DataFrame({\n",
    "    'Id': id_list,\n",
    "    'Pawpularity': pred_list\n",
    "})\n",
    "res.to_csv('./submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 212.640731,
   "end_time": "2021-12-04T12:18:39.555329",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-12-04T12:15:06.914598",
   "version": "2.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
